{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f202f763-92ae-472c-8f5e-6f82e8703c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.7.2 requires smart-open<7.0.0,>=5.2.1, which is not installed.\n",
      "thinc 8.2.2 requires blis<0.8.0,>=0.7.8, which is not installed.\n",
      "weasel 0.3.4 requires smart-open<7.0.0,>=5.2.1, which is not installed.\n",
      "arviz 0.11.2 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.9.0 which is incompatible.\n",
      "jupyterlab-server 2.25.1 requires jsonschema>=4.18.0, but you have jsonschema 4.17.3 which is incompatible.\n",
      "jupyterlab-server 2.25.1 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.2.0 which is incompatible.\n",
      "pep440-version-utils 0.3.0 requires packaging<21.0,>=20.3, but you have packaging 23.2 which is incompatible.\n",
      "rasa 3.5.6 requires attrs<22.2,>=19.3, but you have attrs 23.1.0 which is incompatible.\n",
      "rasa 3.5.6 requires packaging<21.0,>=20.0, but you have packaging 23.2 which is incompatible.\n",
      "rasa 3.5.6 requires scikit-learn<1.2,>=0.22; python_version >= \"3.8\" and python_version < \"3.11\", but you have scikit-learn 1.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain huggingface_hub transformers sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1620ec9c-ab75-49e4-878f-5ff9303d3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "692cc9f4-f154-4bbe-b24a-9f492dbb974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain \n",
    "\n",
    "template = \"\"\" \n",
    "    Question: {question}\n",
    "\n",
    "    Answer: Lets think step by step. \n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabbedf-eba4-4a9d-99e8-7927f7d7674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\",\n",
    "                                        model_kwargs={\"temperature\": 0,\n",
    "                                                      \"max_length\": 64}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3def55e9-1d0c-4d50-a4d0-243903b8f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9811ec-e898-46b0-a17d-6e7a9b69d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What area is the best for growing wine in France?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27448cce-0deb-4b5a-b540-a26c11d74996",
   "metadata": {},
   "source": [
    "### T5-Flan - Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f2e82f5-707a-4b79-a4ce-ce8a8dafeaee",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (1903638726.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    max_length=100\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingfacePipeline\n",
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = 'google/flan-t5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, load_in_8bits=True)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer, \n",
    "    max_length=100\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1fd03-92a7-4954-a65c-a3d119b9921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_llm('What is the capital of France'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa6f5d-ff58-40c7-b663-420dc51fd39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt = prompt,\n",
    "                     llm = local_llm)\n",
    "\n",
    "question = \"What is the capital of England?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c12dfe-7041-4581-9432-40af50379b19",
   "metadata": {},
   "source": [
    "### GPT2 Decoder only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75249046-221f-4873-a6ac-6952f7f155d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"gpt2-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    max_length=100\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71b175-8c1d-4b2a-9238-18a6a731cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt,\n",
    "                     llm=local_llm\n",
    "                    )\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fe0d0b-da4b-4583-86da-62815dbdc33f",
   "metadata": {},
   "source": [
    "### SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4764057d-1ead-4c09-a84f-d02095a7dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "hf.HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc59ca-2302-4962-b157-a0d515fc0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.embed_query('this is an embedding')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
